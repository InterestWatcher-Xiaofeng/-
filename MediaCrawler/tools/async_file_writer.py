import asyncio
import csv
import json
import os
import pathlib
from typing import Dict, List, Optional
import aiofiles
from tools.utils import utils

class AsyncFileWriter:
    def __init__(self, platform: str, crawler_type: str, output_dir: Optional[str] = None):
        self.lock = asyncio.Lock()
        self.platform = platform
        self.crawler_type = crawler_type
        self.output_dir = output_dir  # ðŸ”¥ æ–°å¢žï¼šè‡ªå®šä¹‰è¾“å‡ºç›®å½•
        self.file_paths = {}  # ðŸ”¥ æ–°å¢žï¼šè®°å½•ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„

        # ðŸ”¥ å®šä¹‰CSVåˆ—é¡ºåº
        self.column_orders = {
            "comments": [
                # å‰ä¸‰åˆ—ï¼šæ ‡é¢˜ã€é“¾æŽ¥ã€è¯„è®ºå†…å®¹
                "video_title",
                "video_url",
                "content",
                # è¯„è®ºåŸºæœ¬ä¿¡æ¯
                "comment_id",
                "create_time",
                "ip_location",
                "like_count",
                "sub_comment_count",
                "parent_comment_id",
                # ç”¨æˆ·ä¿¡æ¯
                "nickname",
                "user_id",
                "sec_uid",
                "short_user_id",
                "user_unique_id",
                "user_signature",
                "avatar",
                # è§†é¢‘ä¿¡æ¯
                "aweme_id",
                "video_author",
                "video_liked_count",
                "video_comment_count",
                # å…¶ä»–
                "pictures",
                "last_modify_ts",
            ],
            "contents": [
                # è§†é¢‘å†…å®¹çš„åˆ—é¡ºåºï¼ˆä¿æŒåŽŸæ ·ï¼‰
                "aweme_id",
                "title",
                "desc",
                "create_time",
                "user_id",
                "nickname",
                "avatar",
                "liked_count",
                "comment_count",
                "share_count",
                "collected_count",
                "aweme_type",
                "aweme_url",
                "video_url",
                "video_duration",
                "music_title",
                "music_author",
                "ip_location",
                "last_modify_ts",
            ],
            "creators": [
                # åˆ›ä½œè€…çš„åˆ—é¡ºåºï¼ˆä¿æŒåŽŸæ ·ï¼‰
                "user_id",
                "nickname",
                "gender",
                "avatar",
                "desc",
                "ip_location",
                "follows",
                "fans",
                "interaction",
                "videos_count",
                "last_modify_ts",
            ]
        }

    def _get_file_path(self, file_type: str, item_type: str) -> str:
        # ðŸ”¥ å¦‚æžœå·²ç»ç”Ÿæˆè¿‡è¯¥ç±»åž‹çš„æ–‡ä»¶è·¯å¾„ï¼Œç›´æŽ¥è¿”å›žï¼ˆç¡®ä¿åŒä¸€æ¬¡é‡‡é›†ä½¿ç”¨åŒä¸€ä¸ªæ–‡ä»¶ï¼‰
        cache_key = f"{file_type}_{item_type}"
        if cache_key in self.file_paths:
            return self.file_paths[cache_key]

        # ðŸ”¥ å¦‚æžœè®¾ç½®äº†è‡ªå®šä¹‰è¾“å‡ºç›®å½•ï¼Œä½¿ç”¨è‡ªå®šä¹‰ç›®å½•
        if self.output_dir:
            base_path = self.output_dir
        else:
            base_path = f"data/{self.platform}/{file_type}"

        pathlib.Path(base_path).mkdir(parents=True, exist_ok=True)

        # ðŸ”¥ ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å”¯ä¸€æ–‡ä»¶åï¼ˆæ¯æ¬¡é‡‡é›†éƒ½åˆ›å»ºæ–°æ–‡ä»¶ï¼‰
        import time
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        file_name = f"{self.crawler_type}_{item_type}_{timestamp}.{file_type}"
        file_path = f"{base_path}/{file_name}"

        # ðŸ”¥ è®°å½•æ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨cache_keyä½œä¸ºé”®ï¼‰
        self.file_paths[cache_key] = file_path

        return file_path

    def get_file_paths(self) -> Dict[str, str]:
        """èŽ·å–æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„"""
        return self.file_paths.copy()

    def _get_ordered_fieldnames(self, item: Dict, item_type: str) -> List[str]:
        """
        èŽ·å–æœ‰åºçš„å­—æ®µååˆ—è¡¨

        Args:
            item: æ•°æ®é¡¹å­—å…¸
            item_type: æ•°æ®ç±»åž‹ï¼ˆcomments/contents/creatorsï¼‰

        Returns:
            æœ‰åºçš„å­—æ®µååˆ—è¡¨
        """
        # èŽ·å–é¢„å®šä¹‰çš„åˆ—é¡ºåº
        predefined_order = self.column_orders.get(item_type, [])

        # èŽ·å–å®žé™…æ•°æ®ä¸­çš„æ‰€æœ‰é”®
        actual_keys = list(item.keys())

        # æŒ‰ç…§é¢„å®šä¹‰é¡ºåºæŽ’åˆ—å­˜åœ¨çš„å­—æ®µ
        ordered_fields = [field for field in predefined_order if field in actual_keys]

        # æ·»åŠ é¢„å®šä¹‰é¡ºåºä¸­æ²¡æœ‰çš„å­—æ®µï¼ˆæ”¾åœ¨æœ€åŽï¼‰
        remaining_fields = [field for field in actual_keys if field not in predefined_order]

        return ordered_fields + remaining_fields

    async def write_to_csv(self, item: Dict, item_type: str):
        file_path = self._get_file_path('csv', item_type)
        async with self.lock:
            file_exists = os.path.exists(file_path)

            # ðŸ”¥ ä½¿ç”¨æœ‰åºçš„å­—æ®µå
            fieldnames = self._get_ordered_fieldnames(item, item_type)

            async with aiofiles.open(file_path, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                if not file_exists or await f.tell() == 0:
                    await writer.writeheader()
                await writer.writerow(item)

    async def write_single_item_to_json(self, item: Dict, item_type: str):
        file_path = self._get_file_path('json', item_type)
        async with self.lock:
            existing_data = []
            if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                    try:
                        content = await f.read()
                        if content:
                            existing_data = json.loads(content)
                        if not isinstance(existing_data, list):
                            existing_data = [existing_data]
                    except json.JSONDecodeError:
                        existing_data = []
            
            existing_data.append(item)

            async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(existing_data, ensure_ascii=False, indent=4))