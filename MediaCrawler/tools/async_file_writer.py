import asyncio
import csv
import json
import os
import pathlib
from typing import Dict, List, Optional
import aiofiles
from tools.utils import utils

class AsyncFileWriter:
    def __init__(self, platform: str, crawler_type: str, output_dir: Optional[str] = None):
        self.lock = asyncio.Lock()
        self.platform = platform
        self.crawler_type = crawler_type
        self.output_dir = output_dir  # ğŸ”¥ æ–°å¢ï¼šè‡ªå®šä¹‰è¾“å‡ºç›®å½•
        self.file_paths = {}  # ğŸ”¥ æ–°å¢ï¼šè®°å½•ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„

        # ğŸ”¥ å®šä¹‰CSVåˆ—é¡ºåº
        self.column_orders = {
            "comments": [
                # å‰ä¸‰åˆ—ï¼šæ ‡é¢˜ã€é“¾æ¥ã€è¯„è®ºå†…å®¹
                "video_title",
                "video_url",
                "content",
                # è¯„è®ºåŸºæœ¬ä¿¡æ¯
                "comment_id",
                "create_time",
                "ip_location",
                "like_count",
                "sub_comment_count",
                "parent_comment_id",
                # ç”¨æˆ·ä¿¡æ¯
                "nickname",
                "user_id",
                "sec_uid",
                "short_user_id",
                "user_unique_id",
                "user_signature",
                "avatar",
                # è§†é¢‘ä¿¡æ¯
                "aweme_id",
                "video_author",
                "video_liked_count",
                "video_comment_count",
                # å…¶ä»–
                "pictures",
                "last_modify_ts",
            ],
            "contents": [
                # è§†é¢‘å†…å®¹çš„åˆ—é¡ºåºï¼ˆä¿æŒåŸæ ·ï¼‰
                "aweme_id",
                "title",
                "desc",
                "create_time",
                "user_id",
                "nickname",
                "avatar",
                "liked_count",
                "comment_count",
                "share_count",
                "collected_count",
                "aweme_type",
                "aweme_url",
                "video_url",
                "video_duration",
                "music_title",
                "music_author",
                "ip_location",
                "last_modify_ts",
            ],
            "creators": [
                # åˆ›ä½œè€…çš„åˆ—é¡ºåºï¼ˆä¿æŒåŸæ ·ï¼‰
                "user_id",
                "nickname",
                "gender",
                "avatar",
                "desc",
                "ip_location",
                "follows",
                "fans",
                "interaction",
                "videos_count",
                "last_modify_ts",
            ]
        }

    def _get_file_path(self, file_type: str, item_type: str) -> str:
        # ğŸ”¥ å¦‚æœå·²ç»ç”Ÿæˆè¿‡è¯¥ç±»å‹çš„æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥è¿”å›ï¼ˆç¡®ä¿åŒä¸€æ¬¡é‡‡é›†ä½¿ç”¨åŒä¸€ä¸ªæ–‡ä»¶ï¼‰
        cache_key = f"{file_type}_{item_type}"
        if cache_key in self.file_paths:
            return self.file_paths[cache_key]

        # ğŸ”¥ å¦‚æœè®¾ç½®äº†è‡ªå®šä¹‰è¾“å‡ºç›®å½•ï¼Œä½¿ç”¨è‡ªå®šä¹‰ç›®å½•
        if self.output_dir:
            base_path = self.output_dir
        else:
            base_path = f"data/{self.platform}/{file_type}"

        pathlib.Path(base_path).mkdir(parents=True, exist_ok=True)

        # ğŸ”¥ æ–°å‘½åè§„åˆ™ï¼šå¹³å°_å…³é”®è¯_ç±»å‹_æ—¶é—´æˆ³.æ ¼å¼
        import config
        import re
        import time

        # è·å–å…³é”®è¯å¹¶æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        keywords = getattr(config, 'KEYWORDS', '')
        clean_keywords = re.sub(r'[\\/:*?"<>|\s]+', '_', keywords.strip())
        if not clean_keywords:
            clean_keywords = "æœªå‘½å"

        # å¹³å°åç§°æ˜ å°„
        platform_names = {
            "douyin": "æŠ–éŸ³",
            "xhs": "å°çº¢ä¹¦",
            "kuaishou": "å¿«æ‰‹",
            "bilibili": "Bç«™",
            "weibo": "å¾®åš",
            "tieba": "è´´å§",
            "zhihu": "çŸ¥ä¹"
        }
        platform_name = platform_names.get(self.platform, self.platform)

        # ç±»å‹åç§°æ˜ å°„
        type_names = {
            "comments": "è¯„è®º",
            "contents": "å†…å®¹",
            "creators": "åˆ›ä½œè€…",
            "videos": "è§†é¢‘"
        }
        type_name = type_names.get(item_type, item_type)

        # ğŸ”¥ ç”Ÿæˆæ—¶é—´æˆ³ï¼ˆç¡®ä¿æ¯æ¬¡æœç´¢éƒ½æ˜¯æ–°æ–‡ä»¶ï¼‰
        timestamp = time.strftime("%Y%m%d_%H%M%S")

        # ğŸ”¥ æ–°æ–‡ä»¶åæ ¼å¼ï¼šå¹³å°_å…³é”®è¯_ç±»å‹_æ—¶é—´æˆ³.æ ¼å¼
        file_name = f"{platform_name}_{clean_keywords}_{type_name}_{timestamp}.{file_type}"
        file_path = f"{base_path}/{file_name}"

        # ğŸ”¥ è®°å½•æ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨cache_keyä½œä¸ºé”®ï¼‰
        self.file_paths[cache_key] = file_path

        return file_path

    def get_file_paths(self) -> Dict[str, str]:
        """è·å–æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„"""
        return self.file_paths.copy()

    def _get_ordered_fieldnames(self, item: Dict, item_type: str) -> List[str]:
        """
        è·å–æœ‰åºçš„å­—æ®µååˆ—è¡¨

        Args:
            item: æ•°æ®é¡¹å­—å…¸
            item_type: æ•°æ®ç±»å‹ï¼ˆcomments/contents/creatorsï¼‰

        Returns:
            æœ‰åºçš„å­—æ®µååˆ—è¡¨
        """
        # è·å–é¢„å®šä¹‰çš„åˆ—é¡ºåº
        predefined_order = self.column_orders.get(item_type, [])

        # è·å–å®é™…æ•°æ®ä¸­çš„æ‰€æœ‰é”®
        actual_keys = list(item.keys())

        # æŒ‰ç…§é¢„å®šä¹‰é¡ºåºæ’åˆ—å­˜åœ¨çš„å­—æ®µ
        ordered_fields = [field for field in predefined_order if field in actual_keys]

        # æ·»åŠ é¢„å®šä¹‰é¡ºåºä¸­æ²¡æœ‰çš„å­—æ®µï¼ˆæ”¾åœ¨æœ€åï¼‰
        remaining_fields = [field for field in actual_keys if field not in predefined_order]

        return ordered_fields + remaining_fields

    async def write_to_csv(self, item: Dict, item_type: str):
        file_path = self._get_file_path('csv', item_type)
        async with self.lock:
            file_exists = os.path.exists(file_path)

            # ğŸ”¥ ä½¿ç”¨æœ‰åºçš„å­—æ®µå
            fieldnames = self._get_ordered_fieldnames(item, item_type)

            async with aiofiles.open(file_path, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                if not file_exists or await f.tell() == 0:
                    await writer.writeheader()
                await writer.writerow(item)

    async def write_single_item_to_json(self, item: Dict, item_type: str):
        file_path = self._get_file_path('json', item_type)
        async with self.lock:
            existing_data = []
            if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                    try:
                        content = await f.read()
                        if content:
                            existing_data = json.loads(content)
                        if not isinstance(existing_data, list):
                            existing_data = [existing_data]
                    except json.JSONDecodeError:
                        existing_data = []
            
            existing_data.append(item)

            async with aiofiles.open(file_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(existing_data, ensure_ascii=False, indent=4))