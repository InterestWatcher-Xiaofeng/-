# V1.2.3 更新说明

**发布日期:** 2025-11-03  
**版本号:** v1.2.3  
**更新类型:** 🐛 Bug修复 + ✨ 功能优化

---

## 📋 更新概述

本次更新主要解决了长时间采集任务的超时问题,并新增了实时进度显示功能,大幅提升了用户体验。

---

## 🔧 核心修复

### 1. 修复长时间采集任务超时问题 ✅

**问题描述:**
- 当采集视频数量较多或采集时间超过10分钟时,GUI界面会显示"采集过程中出错"
- 但后台任务实际上还在正常运行
- 进度条消失,用户无法看到采集进度

**问题原因:**
- `future.result(timeout=600)` 设置了10分钟超时限制
- 超时后GUI抛出异常,但后台异步任务继续运行

**解决方案:**
- 移除 `timeout` 参数,改为 `future.result()`
- 任务会一直等待直到完成,不会因为时间长而中断

**影响范围:**
- 关键词搜索模式
- 多链接采集模式
- 创作者主页模式

**修改文件:**
- `gui_app.py` (第1495行, 第1525行)

---

### 2. 新增实时进度显示功能 ✨

**功能描述:**
- 终端实时显示当前正在采集第几个视频
- 显示总视频数量和当前进度
- 显示每个视频的采集状态(开始/完成/失败)

**终端输出示例:**
```
📊 开始采集 20 个视频的评论

🎬 [1/20] 正在采集视频 7461508836659137844 的评论...
   💬 [1/20] 开始获取视频 7461508836659137844 的评论...
   ✅ [1/20] 视频 7461508836659137844 评论采集完成

🎬 [2/20] 正在采集视频 7458306274963246387 的评论...
   💬 [2/20] 开始获取视频 7458306274963246387 的评论...
   ✅ [2/20] 视频 7458306274963246387 评论采集完成

...

✅ 所有 20 个视频的评论采集完成!
```

**修改文件:**
- `media_platform/douyin/core.py` (第250-275行, 第277-306行)

**技术实现:**
- 在 `batch_get_note_comments` 方法中添加总数显示
- 在 `get_comments` 方法中添加 `index` 和 `total` 参数
- 使用 `enumerate` 遍历视频列表,获取当前索引

---

## 📊 详细修改记录

### 修改1: gui_app.py

**位置:** 第1488-1495行 (多链接批量采集)

```python
# ❌ 旧代码
future.result(timeout=600)

# ✅ 新代码
# 🔥 移除超时限制,等待任务完成
future.result()
```

**位置:** 第1518-1525行 (关键词/创作者逐个采集)

```python
# ❌ 旧代码
# 等待完成(最多10分钟)
future.result(timeout=600)

# ✅ 新代码
# 🔥 移除超时限制,等待任务完成
future.result()
```

---

### 修改2: media_platform/douyin/core.py

**位置:** 第250-275行 (batch_get_note_comments 方法)

```python
async def batch_get_note_comments(self, aweme_list: List[str]) -> None:
    """
    Batch get note comments
    """
    if not config.ENABLE_GET_COMMENTS:
        utils.logger.info(f"[DouYinCrawler.batch_get_note_comments] Crawling comment mode is not enabled")
        return

    # 🔥 显示总数
    total_videos = len(aweme_list)
    utils.logger.info(f"[DouYinCrawler.batch_get_note_comments] 开始采集 {total_videos} 个视频的评论")
    print(f"\n📊 开始采集 {total_videos} 个视频的评论\n")

    task_list: List[Task] = []
    semaphore = asyncio.Semaphore(config.MAX_CONCURRENCY_NUM)
    for index, aweme_id in enumerate(aweme_list, 1):
        # 🔥 显示当前进度
        print(f"🎬 [{index}/{total_videos}] 正在采集视频 {aweme_id} 的评论...")
        utils.logger.info(f"[DouYinCrawler.batch_get_note_comments] [{index}/{total_videos}] 正在采集视频 {aweme_id}")
        
        task = asyncio.create_task(self.get_comments(aweme_id, semaphore, index, total_videos), name=aweme_id)
        task_list.append(task)
    if len(task_list) > 0:
        await asyncio.wait(task_list)
    
    print(f"\n✅ 所有 {total_videos} 个视频的评论采集完成!\n")
```

**位置:** 第277-306行 (get_comments 方法)

```python
async def get_comments(self, aweme_id: str, semaphore: asyncio.Semaphore, index: int = 0, total: int = 0) -> None:
    async with semaphore:
        try:
            # 🔥 显示开始采集
            if index > 0 and total > 0:
                print(f"   💬 [{index}/{total}] 开始获取视频 {aweme_id} 的评论...")
            
            # ... 原有代码 ...
            
            # 🔥 显示完成
            if index > 0 and total > 0:
                print(f"   ✅ [{index}/{total}] 视频 {aweme_id} 评论采集完成")
            
        except DataFetchError as e:
            utils.logger.error(f"[DouYinCrawler.get_comments] aweme_id: {aweme_id} get comments failed, error: {e}")
            if index > 0 and total > 0:
                print(f"   ❌ [{index}/{total}] 视频 {aweme_id} 评论采集失败: {e}")
```

---

## ⚠️ 注意事项

### 1. 无超时限制

- **优点:** 不会因为采集时间长而中断任务
- **缺点:** 如果任务卡死,需要手动点击"停止采集"按钮
- **建议:** 采集大量视频时,建议分批次采集

### 2. GUI响应性

- 采集过程中GUI可能看起来"无响应",这是正常现象
- 后台任务正在正常运行,请查看终端输出确认进度
- 不要关闭终端窗口,否则会中断采集任务

### 3. 进度显示

- 进度显示仅在终端中可见
- GUI界面暂时没有进度条更新(后续版本会优化)
- 建议采集时保持终端窗口可见

---

## 🧪 测试建议

### 测试1: 长时间采集任务

1. 选择"创作者主页"模式
2. 输入一个创作者链接
3. 设置采集20个视频,每个视频50条评论
4. 观察是否会超时报错
5. 预计采集时间: 15-30分钟

### 测试2: 进度显示

1. 选择"多链接采集"模式
2. 输入10条视频链接
3. 设置每个视频10条评论
4. 观察终端输出,确认显示 `[1/10]`, `[2/10]`, ...
5. 确认显示视频ID和采集状态

### 测试3: 停止功能

1. 开始一个长时间采集任务
2. 采集过程中点击"停止采集"按钮
3. 确认任务能正常停止
4. 确认已采集的数据已保存

---

## 📈 性能影响

- **内存占用:** 无变化
- **CPU占用:** 无变化
- **采集速度:** 无变化
- **稳定性:** 提升 ⬆️ (不会因超时而中断)

---

## 🔄 兼容性

- ✅ 向后兼容,不影响现有功能
- ✅ 不需要重新配置
- ✅ 不需要重新登录
- ✅ 已有的CSV文件格式不变

---

## 📝 后续计划

### 短期计划 (v1.2.4)
- [ ] GUI界面添加实时进度条
- [ ] 添加预计剩余时间显示
- [ ] 优化停止采集的响应速度

### 中期计划 (v1.3.0)
- [ ] 支持暂停/恢复采集
- [ ] 支持断点续传
- [ ] 添加采集速度控制

### 长期计划 (v2.0.0)
- [ ] 支持小红书平台
- [ ] 支持B站平台
- [ ] 添加数据分析功能

---

## 🙏 致谢

感谢所有用户的反馈和建议,你们的支持是我们持续改进的动力!

如果遇到任何问题,请在 [GitHub Issues](https://github.com/InterestWatcher-Xiaofeng/MediaCrawler/issues) 中反馈。

---

**更新日期:** 2025-11-03  
**版本号:** v1.2.3  
**维护者:** InterestWatcher-Xiaofeng

