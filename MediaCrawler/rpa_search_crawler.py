"""
RPAæ¨¡å¼æœç´¢çˆ¬è™« - æ··åˆæ–¹æ¡ˆ
åŠŸèƒ½: ä½¿ç”¨RPAæ¨¡å¼æœç´¢å…³é”®è¯,è·å–è§†é¢‘é“¾æ¥,ç„¶åç”¨Detailæ¨¡å¼æŠ“å–è¯„è®º
"""

import asyncio
import re
import json
from pathlib import Path
from typing import List, Dict
from playwright.async_api import async_playwright, Page, Browser
from datetime import datetime

from config import base_config


class RPASearchCrawler:
    """RPAæ¨¡å¼æœç´¢çˆ¬è™«"""
    
    def __init__(self, keyword: str, max_videos: int = 20):
        self.keyword = keyword
        self.max_videos = max_videos
        self.video_links = []
        self.browser = None
        self.context = None
        self.page = None
        
    async def start(self):
        """å¯åŠ¨çˆ¬è™«"""
        print("=" * 60)
        print("ğŸš€ RPAæ¨¡å¼æœç´¢çˆ¬è™«å¯åŠ¨")
        print("=" * 60)
        print(f"ğŸ” å…³é”®è¯: {self.keyword}")
        print(f"ğŸ¬ ç›®æ ‡è§†é¢‘æ•°: {self.max_videos}")
        print("=" * 60)
        
        async with async_playwright() as playwright:
            # å¯åŠ¨æµè§ˆå™¨
            await self._launch_browser(playwright)
            
            # è®¿é—®æŠ–éŸ³æœç´¢é¡µ
            await self._goto_search_page()
            
            # ç­‰å¾…ç”¨æˆ·ç™»å½•
            await self._wait_for_login()
            
            # æ‰§è¡Œæœç´¢
            await self._search_keyword()
            
            # æ»šåŠ¨åŠ è½½è§†é¢‘
            await self._scroll_and_collect_links()
            
            # ä¿å­˜é“¾æ¥
            self._save_links()
            
            # å…³é—­æµè§ˆå™¨
            await self._close_browser()
            
        return self.video_links
    
    async def _launch_browser(self, playwright):
        """å¯åŠ¨æµè§ˆå™¨"""
        print("\nğŸ“± æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
        
        self.browser = await playwright.chromium.launch(
            headless=False,  # æ˜¾ç¤ºæµè§ˆå™¨
            channel="chrome"  # ä½¿ç”¨Chrome
        )
        
        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
        self.context = await self.browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        )
        
        # åˆ›å»ºé¡µé¢
        self.page = await self.context.new_page()
        
        print("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
    
    async def _goto_search_page(self):
        """è®¿é—®æŠ–éŸ³æœç´¢é¡µ"""
        print("\nğŸŒ æ­£åœ¨è®¿é—®æŠ–éŸ³æœç´¢é¡µ...")

        url = "https://www.douyin.com/"
        try:
            await self.page.goto(url, timeout=60000)  # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°60ç§’
            await asyncio.sleep(3)  # ç­‰å¾…é¡µé¢ç¨³å®š
        except Exception as e:
            print(f"âš ï¸ é¡µé¢åŠ è½½è¶…æ—¶,ç»§ç»­æ‰§è¡Œ: {e}")

        print("âœ… é¡µé¢åŠ è½½å®Œæˆ")
    
    async def _wait_for_login(self):
        """ç­‰å¾…ç”¨æˆ·ç™»å½•"""
        print("\nğŸ” è¯·åœ¨æµè§ˆå™¨ä¸­ç™»å½•æŠ–éŸ³...")
        print("   æç¤º: å¦‚æœå·²ç»ç™»å½•,è¯·æŒ‰Enterç»§ç»­")
        
        # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
        try:
            # ç­‰å¾…ç”¨æˆ·å¤´åƒå…ƒç´ å‡ºç°(è¡¨ç¤ºå·²ç™»å½•)
            await self.page.wait_for_selector(
                'div[class*="avatar"]',
                timeout=60000  # ç­‰å¾…60ç§’
            )
            print("âœ… æ£€æµ‹åˆ°ç™»å½•çŠ¶æ€")
        except:
            print("âš ï¸ æœªæ£€æµ‹åˆ°ç™»å½•,è¯·æ‰‹åŠ¨ç™»å½•åæŒ‰Enterç»§ç»­")
            input("æŒ‰Enterç»§ç»­...")
    
    async def _search_keyword(self):
        """æ‰§è¡Œæœç´¢"""
        print(f"\nğŸ” æ­£åœ¨æœç´¢å…³é”®è¯: {self.keyword}")

        # æ–¹æ³•1: ç›´æ¥è®¿é—®æœç´¢ç»“æœé¡µ
        search_url = f"https://www.douyin.com/search/{self.keyword}?type=video"
        try:
            await self.page.goto(search_url, timeout=60000)
            await asyncio.sleep(5)  # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
        except Exception as e:
            print(f"âš ï¸ æœç´¢é¡µé¢åŠ è½½è¶…æ—¶,ç»§ç»­æ‰§è¡Œ: {e}")

        # ğŸ”¥ æ–°å¢: ç‚¹å‡»"æœ€å¤šç‚¹èµ"ç­›é€‰
        await self._click_most_liked_filter()

        print("âœ… æœç´¢å®Œæˆ")

    async def _click_most_liked_filter(self):
        """ç‚¹å‡»æœ€å¤šç‚¹èµç­›é€‰æŒ‰é’®"""
        print("\nğŸ¯ æ­£åœ¨è®¾ç½®ç­›é€‰æ¡ä»¶: æœ€å¤šç‚¹èµ...")

        try:
            # æ–¹æ³•1: å°è¯•ä½¿ç”¨ä½ æä¾›çš„CSSé€‰æ‹©å™¨
            filter_selector = "#search-toolbar-container > div.ZyB0s4zV > div > div > div.jjU9T0dQ > span"

            # ç­‰å¾…ç­›é€‰æŒ‰é’®å‡ºç°
            try:
                await self.page.wait_for_selector(filter_selector, timeout=5000)
                print("   âœ… æ‰¾åˆ°ç­›é€‰æŒ‰é’®(æ–¹æ³•1)")
            except:
                # æ–¹æ³•2: ä½¿ç”¨æ›´é€šç”¨çš„é€‰æ‹©å™¨
                print("   âš ï¸ æ–¹æ³•1å¤±è´¥,å°è¯•æ–¹æ³•2...")
                filter_selector = "span:has-text('ç»¼åˆæ’åº')"
                try:
                    await self.page.wait_for_selector(filter_selector, timeout=5000)
                    print("   âœ… æ‰¾åˆ°ç­›é€‰æŒ‰é’®(æ–¹æ³•2)")
                except:
                    # æ–¹æ³•3: ä½¿ç”¨æ–‡æœ¬åŒ¹é…
                    print("   âš ï¸ æ–¹æ³•2å¤±è´¥,å°è¯•æ–¹æ³•3...")
                    filter_selector = "text=ç»¼åˆæ’åº"
                    try:
                        await self.page.wait_for_selector(filter_selector, timeout=5000)
                        print("   âœ… æ‰¾åˆ°ç­›é€‰æŒ‰é’®(æ–¹æ³•3)")
                    except:
                        print("   âŒ æœªæ‰¾åˆ°ç­›é€‰æŒ‰é’®,è·³è¿‡ç­›é€‰")
                        return

            # ç‚¹å‡»ç­›é€‰æŒ‰é’®
            await self.page.click(filter_selector)
            await asyncio.sleep(1)  # ç­‰å¾…ä¸‹æ‹‰èœå•å‡ºç°
            print("   âœ… å·²ç‚¹å‡»ç­›é€‰æŒ‰é’®")

            # ç‚¹å‡»"æœ€å¤šç‚¹èµ"é€‰é¡¹
            most_liked_selector = "text=æœ€å¤šç‚¹èµ"
            try:
                await self.page.wait_for_selector(most_liked_selector, timeout=3000)
                await self.page.click(most_liked_selector)
                await asyncio.sleep(2)  # ç­‰å¾…é¡µé¢é‡æ–°åŠ è½½
                print("   âœ… å·²é€‰æ‹©'æœ€å¤šç‚¹èµ'æ’åº")
            except:
                print("   âš ï¸ æœªæ‰¾åˆ°'æœ€å¤šç‚¹èµ'é€‰é¡¹,ä½¿ç”¨é»˜è®¤æ’åº")

        except Exception as e:
            print(f"   âš ï¸ ç­›é€‰è®¾ç½®å¤±è´¥: {e}")
            print("   â„¹ï¸ å°†ä½¿ç”¨é»˜è®¤æ’åºç»§ç»­")
    
    async def _check_captcha(self):
        """ğŸ”¥ æ£€æµ‹æ˜¯å¦å‡ºç°çœŸäººéªŒè¯"""
        try:
            # æ£€æµ‹å¸¸è§çš„éªŒè¯ç å…ƒç´ 
            captcha_selectors = [
                "text=æ»‘åŠ¨å®ŒæˆéªŒè¯",
                "text=ç‚¹å‡»å®ŒæˆéªŒè¯",
                "text=æ‹–åŠ¨æ»‘å—",
                "[class*='captcha']",
                "[class*='verify']",
                "[id*='captcha']"
            ]

            for selector in captcha_selectors:
                try:
                    element = await self.page.query_selector(selector)
                    if element:
                        print("\n" + "="*60)
                        print("âš ï¸  æ£€æµ‹åˆ°çœŸäººéªŒè¯!")
                        print("="*60)
                        print("è¯·åœ¨æµè§ˆå™¨ä¸­å®ŒæˆéªŒè¯,ç„¶åæŒ‰Enterç»§ç»­...")
                        print("="*60)
                        input()
                        print("âœ… ç»§ç»­æ‰§è¡Œ...")
                        return True
                except:
                    continue
            return False
        except Exception as e:
            print(f"âš ï¸ éªŒè¯æ£€æµ‹å¤±è´¥: {e}")
            return False

    async def _scroll_and_collect_links(self):
        """æ»šåŠ¨é¡µé¢å¹¶æ”¶é›†è§†é¢‘é“¾æ¥"""
        print(f"\nğŸ“œ æ­£åœ¨æ”¶é›†è§†é¢‘é“¾æ¥ (ç›®æ ‡: {self.max_videos}ä¸ª)...")

        # ğŸ”¥ å…ˆæ£€æŸ¥æ˜¯å¦æœ‰çœŸäººéªŒè¯
        await self._check_captcha()

        collected_count = 0
        scroll_count = 0
        max_scrolls = 50  # æœ€å¤§æ»šåŠ¨æ¬¡æ•°
        
        while collected_count < self.max_videos and scroll_count < max_scrolls:
            # æå–å½“å‰é¡µé¢çš„è§†é¢‘é“¾æ¥
            new_links = await self._extract_video_links()
            
            # æ·»åŠ æ–°é“¾æ¥
            for link in new_links:
                if link not in self.video_links:
                    self.video_links.append(link)
                    collected_count = len(self.video_links)
                    print(f"   âœ… å·²æ”¶é›†: {collected_count}/{self.max_videos} - {link}")
                    
                    if collected_count >= self.max_videos:
                        break
            
            # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡æ•°é‡,é€€å‡º
            if collected_count >= self.max_videos:
                break
            
            # æ»šåŠ¨é¡µé¢
            await self.page.evaluate("window.scrollBy(0, 1000)")
            await asyncio.sleep(2)  # ç­‰å¾…åŠ è½½
            scroll_count += 1
            
            print(f"   ğŸ“œ æ»šåŠ¨æ¬¡æ•°: {scroll_count}, å·²æ”¶é›†: {collected_count}")
        
        print(f"\nâœ… æ”¶é›†å®Œæˆ! å…±æ”¶é›† {len(self.video_links)} ä¸ªè§†é¢‘é“¾æ¥")
    
    async def _extract_video_links(self) -> List[str]:
        """æå–å½“å‰é¡µé¢çš„è§†é¢‘é“¾æ¥"""
        
        # æ–¹æ³•1: ä»æœç´¢ç»“æœåˆ—è¡¨æå–
        links = await self.page.evaluate("""
            () => {
                const links = [];
                
                // æŸ¥æ‰¾æ‰€æœ‰è§†é¢‘é“¾æ¥
                const videoElements = document.querySelectorAll('a[href*="/video/"]');
                
                videoElements.forEach(el => {
                    const href = el.getAttribute('href');
                    if (href && href.includes('/video/')) {
                        // æå–å®Œæ•´é“¾æ¥
                        const fullUrl = href.startsWith('http') 
                            ? href 
                            : 'https://www.douyin.com' + href;
                        links.push(fullUrl);
                    }
                });
                
                return links;
            }
        """)
        
        # å»é‡å¹¶è¿”å›
        unique_links = list(set(links))
        return unique_links
    
    def _save_links(self):
        """ä¿å­˜é“¾æ¥åˆ°æ–‡ä»¶"""
        print("\nğŸ’¾ æ­£åœ¨ä¿å­˜è§†é¢‘é“¾æ¥...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("data/douyin/links")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"video_links_{self.keyword}_{timestamp}.txt"
        filepath = output_dir / filename
        
        # ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# å…³é”®è¯: {self.keyword}\n")
            f.write(f"# æ”¶é›†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"# è§†é¢‘æ•°é‡: {len(self.video_links)}\n")
            f.write("\n")
            for link in self.video_links:
                f.write(f"{link}\n")
        
        # ä¿å­˜ä¸ºJSONæ ¼å¼
        json_filename = f"video_links_{self.keyword}_{timestamp}.json"
        json_filepath = output_dir / json_filename
        
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump({
                "keyword": self.keyword,
                "collect_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "video_count": len(self.video_links),
                "video_links": self.video_links
            }, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… é“¾æ¥å·²ä¿å­˜:")
        print(f"   ğŸ“„ æ–‡æœ¬æ–‡ä»¶: {filepath}")
        print(f"   ğŸ“„ JSONæ–‡ä»¶: {json_filepath}")
        
        # åŒæ—¶æ›´æ–°åˆ°é…ç½®æ–‡ä»¶
        self._update_config()
    
    def _update_config(self):
        """æ›´æ–°é…ç½®æ–‡ä»¶"""
        print("\nâš™ï¸ æ­£åœ¨æ›´æ–°é…ç½®æ–‡ä»¶...")
        
        config_file = Path("config/dy_config.py")
        
        # è¯»å–é…ç½®æ–‡ä»¶
        with open(config_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç”Ÿæˆæ–°çš„è§†é¢‘åˆ—è¡¨
        links_str = ",\n    ".join([f'"{link}"' for link in self.video_links[:self.max_videos]])
        new_list = f'DY_SPECIFIED_ID_LIST = [\n    {links_str}\n]'
        
        # æ›¿æ¢é…ç½®
        pattern = r'DY_SPECIFIED_ID_LIST\s*=\s*\[.*?\]'
        new_content = re.sub(pattern, new_list, content, flags=re.DOTALL)
        
        # å†™å›é…ç½®æ–‡ä»¶
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print(f"âœ… é…ç½®æ–‡ä»¶å·²æ›´æ–°: {config_file}")
        print(f"   å·²æ·»åŠ  {len(self.video_links[:self.max_videos])} ä¸ªè§†é¢‘é“¾æ¥")
    
    async def _close_browser(self):
        """å…³é—­æµè§ˆå™¨"""
        print("\nğŸ”’ æ­£åœ¨å…³é—­æµè§ˆå™¨...")
        
        if self.browser:
            await self.browser.close()
        
        print("âœ… æµè§ˆå™¨å·²å…³é—­")


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ¯" * 30)
    print("RPAæ¨¡å¼æœç´¢çˆ¬è™« - æ··åˆæ–¹æ¡ˆ")
    print("ğŸ¯" * 30)
    
    # ä»é…ç½®è¯»å–å‚æ•°
    keyword = base_config.KEYWORDS.split(',')[0].strip()  # å–ç¬¬ä¸€ä¸ªå…³é”®è¯
    max_videos = base_config.CRAWLER_MAX_NOTES_COUNT
    
    print(f"\nğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   å…³é”®è¯: {keyword}")
    print(f"   è§†é¢‘æ•°é‡: {max_videos}")
    
    # åˆ›å»ºçˆ¬è™«
    crawler = RPASearchCrawler(keyword=keyword, max_videos=max_videos)
    
    # æ‰§è¡Œæœç´¢
    video_links = await crawler.start()
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ‰ RPAæœç´¢å®Œæˆ!")
    print("=" * 60)
    print(f"âœ… å…±æ”¶é›† {len(video_links)} ä¸ªè§†é¢‘é“¾æ¥")
    print("\nğŸ“ ä¸‹ä¸€æ­¥:")
    print("   1. è§†é¢‘é“¾æ¥å·²è‡ªåŠ¨æ›´æ–°åˆ° config/dy_config.py")
    print("   2. è¿è¡Œä»¥ä¸‹å‘½ä»¤å¼€å§‹æŠ“å–è¯„è®º:")
    print("      python main.py --platform dy --lt qrcode --type detail")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())

